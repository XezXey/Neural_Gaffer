{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f3e4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sh_utils import get_shcoeff, unfold_sh_coeff, flatten_sh_coeff, apply_integrate_conv, sample_from_sh, genSurfaceNormals, cartesian_to_spherical, from_x_left_to_z_up\n",
    "from tonemapper import TonemapHDR\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "\n",
    "ORDER = 2\n",
    "map_name = \"117_hdrmaps_com_free_2K.exr\"\n",
    "# map_name = \"128_hdrmaps_com_free_2K.exr\"\n",
    "# map_name = \"125_hdrmaps_com_free_2K.exr\"\n",
    "\n",
    "tonemapper = TonemapHDR()\n",
    "\n",
    "hdr_map = f\"/home/mint/Dev/DiFaReli++/TPAMI_baseline_MajorRevision/Neural_Gaffer/demo/environment_map_sample/{map_name}\"\n",
    "hdr_image = skimage.io.imread(hdr_map)\n",
    "hdr_image = skimage.img_as_float(hdr_image)\n",
    "# Roll hdr 180 deg\n",
    "hdr_image = np.roll(hdr_image, shift=-(hdr_image.shape[1] // 2), axis=1)\n",
    "print(\"HDR Image Shape: \", hdr_image.shape)\n",
    "print(np.max(hdr_image), np.min(hdr_image))\n",
    "plt.imshow(hdr_image)\n",
    "plt.title(\"HDR Image\")\n",
    "plt.show()\n",
    "hdr_tm, _, _ = tonemapper(hdr_image)\n",
    "plt.imshow(hdr_tm)\n",
    "plt.title(\"Tonemapped HDR Image\")\n",
    "plt.show()\n",
    "\n",
    "coeff = get_shcoeff(hdr_image, Lmax=2)\n",
    "sh = flatten_sh_coeff(coeff, max_sh_level=2)\n",
    "# sh = np.load(f'./shcoeffs/{map_name}.npy')\n",
    "print(\"Shape: \", sh.shape)\n",
    "print(\"SH: \", sh)\n",
    "print(\"SH.T: \", sh.T)\n",
    "\n",
    "unfolded = unfold_sh_coeff(sh, max_sh_level=2)\n",
    "print(unfolded.shape)\n",
    "print(unfolded[0][0])\n",
    "print(unfolded[0][1])\n",
    "\n",
    "# print(unfolded[1][0])\n",
    "# print(unfolded[1][1])\n",
    "\n",
    "# print(unfolded[2][1])\n",
    "# print(unfolded[2][0])\n",
    "\n",
    "apply_integrated = apply_integrate_conv(unfolded.copy())\n",
    "print(apply_integrated.shape)\n",
    "print(apply_integrated[0][0])\n",
    "# print(unfolded[0][0] * np.pi)\n",
    "# print(apply_integrated[0][1])\n",
    "\n",
    "normal_map = genSurfaceNormals(128).permute(1, 2, 0).cpu().numpy()\n",
    "# normal_map = from_x_left_to_z_up(normal_map)\n",
    "mask = (normal_map[..., 2:3] != 0)\n",
    "print(normal_map.max(), normal_map.min())\n",
    "plt.imshow(((normal_map + 1) * 0.5) * mask)\n",
    "plt.title(\"Normal Map\")\n",
    "plt.show()\n",
    "\n",
    "theta, phi = cartesian_to_spherical(normal_map)\n",
    "shading = sample_from_sh(apply_integrated, lmax=ORDER, theta=theta, phi=phi)\n",
    "plt.imshow(shading * mask)\n",
    "plt.title(\"Shading from SH Coefficients\")\n",
    "plt.show()\n",
    "\n",
    "# #ezexr.imwrite(output_path.replace(\".png\",\".exr\"), shading)   \n",
    "shading = np.float32(shading)\n",
    "print(shading.shape, np.max(shading), np.min(shading))\n",
    "shading, _, _ = tonemapper(shading) # tonemap\n",
    "print(shading.shape, np.max(shading), np.min(shading))\n",
    "\n",
    "plt.imshow(shading * mask)\n",
    "plt.title(\"Shading from Tonemapped HDR\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8989f2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.984252..0.999938].\n",
      "/tmp/ipykernel_2837508/2610975643.py:38: MatplotlibDeprecationWarning: The tostring_rgb function was deprecated in Matplotlib 3.8 and will be removed in 3.10. Use buffer_rgba instead.\n",
      "  buf = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
      "  3%|▎         | 1/30 [00:00<00:27,  1.06it/s]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.984252..0.999938].\n",
      "  7%|▋         | 2/30 [00:01<00:25,  1.10it/s]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.984252..0.999938].\n",
      " 10%|█         | 3/30 [00:02<00:24,  1.11it/s]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.984252..0.999938].\n",
      " 13%|█▎        | 4/30 [00:03<00:23,  1.11it/s]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.984252..0.999938].\n",
      " 17%|█▋        | 5/30 [00:04<00:22,  1.12it/s]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.984252..0.999938].\n",
      " 20%|██        | 6/30 [00:05<00:21,  1.11it/s]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.984252..0.999938].\n",
      " 23%|██▎       | 7/30 [00:06<00:22,  1.02it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 50\u001b[0m\n\u001b[1;32m     48\u001b[0m hdr_image_roll \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mroll(hdr_image\u001b[38;5;241m.\u001b[39mcopy(), shift\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mi, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     49\u001b[0m hdr_image_roll, _, _ \u001b[38;5;241m=\u001b[39m tonemapper(hdr_image_roll)\n\u001b[0;32m---> 50\u001b[0m normal_map, shading \u001b[38;5;241m=\u001b[39m \u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhdr_image_roll\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# make one figure with 3 panels\u001b[39;00m\n\u001b[1;32m     53\u001b[0m fig, axes \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m3\u001b[39m), dpi\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\n",
      "Cell \u001b[0;32mIn[26], line 28\u001b[0m, in \u001b[0;36mrender\u001b[0;34m(hdr_image)\u001b[0m\n\u001b[1;32m     25\u001b[0m mask \u001b[38;5;241m=\u001b[39m (normal_map[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m2\u001b[39m:\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     27\u001b[0m theta, phi \u001b[38;5;241m=\u001b[39m cartesian_to_spherical(normal_map)\n\u001b[0;32m---> 28\u001b[0m shading \u001b[38;5;241m=\u001b[39m \u001b[43msample_from_sh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapply_integrated\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mORDER\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mphi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m shading \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32(shading)\n\u001b[1;32m     31\u001b[0m shading, _, _ \u001b[38;5;241m=\u001b[39m tonemapper(shading) \u001b[38;5;66;03m# tonemap\u001b[39;00m\n",
      "File \u001b[0;32m~/Dev/DiFaReli++/TPAMI_baseline_MajorRevision/Neural_Gaffer/difareli++/envmap2sh/sh_utils.py:113\u001b[0m, in \u001b[0;36msample_from_sh\u001b[0;34m(shcoeff, lmax, theta, phi)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ch \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m)):\n\u001b[1;32m    112\u001b[0m     coeffs \u001b[38;5;241m=\u001b[39m pyshtools\u001b[38;5;241m.\u001b[39mSHCoeffs\u001b[38;5;241m.\u001b[39mfrom_array(shcoeff[ch], lmax\u001b[38;5;241m=\u001b[39mlmax, normalization\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4pi\u001b[39m\u001b[38;5;124m'\u001b[39m, csphase\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 113\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mcoeffs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGLQ\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mphi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlmax_calc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlmax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdegrees\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     output\u001b[38;5;241m.\u001b[39mappend(image[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\u001b[38;5;28;01mNone\u001b[39;00m])\n\u001b[1;32m    115\u001b[0m output \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(output, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/neural-gaffer/lib/python3.9/site-packages/pyshtools/shclasses/shcoeffs.py:2210\u001b[0m, in \u001b[0;36mSHCoeffs.expand\u001b[0;34m(self, grid, lat, colat, lon, degrees, zeros, lmax, lmax_calc, extend, backend, nthreads)\u001b[0m\n\u001b[1;32m   2207\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2208\u001b[0m             lat \u001b[38;5;241m=\u001b[39m temp \u001b[38;5;241m-\u001b[39m colat\n\u001b[0;32m-> 2210\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_expand_coord\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdegrees\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdegrees\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2211\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mlmax_calc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlmax_calc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values\n\u001b[1;32m   2214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/neural-gaffer/lib/python3.9/site-packages/pyshtools/shclasses/shcoeffs.py:4174\u001b[0m, in \u001b[0;36mSHRealCoeffs._expand_coord\u001b[0;34m(self, lat, lon, lmax_calc, degrees)\u001b[0m\n\u001b[1;32m   4171\u001b[0m     values \u001b[38;5;241m=\u001b[39m _np\u001b[38;5;241m.\u001b[39mempty_like(lat, dtype\u001b[38;5;241m=\u001b[39m_np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m   4172\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m v, latitude, longitude \u001b[38;5;129;01min\u001b[39;00m _np\u001b[38;5;241m.\u001b[39mnditer([values, latin, lonin],\n\u001b[1;32m   4173\u001b[0m                                              op_flags\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreadwrite\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[0;32m-> 4174\u001b[0m         v[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43m_shtools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMakeGridPoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoeffs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlatitude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4175\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mlon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlongitude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4176\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mlmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlmax_calc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4177\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mcsphase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsphase\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values\n\u001b[1;32m   4179\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(lat) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mlist\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/neural-gaffer/lib/python3.9/site-packages/numpy/lib/function_base.py:2372\u001b[0m, in \u001b[0;36mvectorize.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2369\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_stage_2(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2370\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m-> 2372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_as_normal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/neural-gaffer/lib/python3.9/site-packages/numpy/lib/function_base.py:2365\u001b[0m, in \u001b[0;36mvectorize._call_as_normal\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2362\u001b[0m     vargs \u001b[38;5;241m=\u001b[39m [args[_i] \u001b[38;5;28;01mfor\u001b[39;00m _i \u001b[38;5;129;01min\u001b[39;00m inds]\n\u001b[1;32m   2363\u001b[0m     vargs\u001b[38;5;241m.\u001b[39mextend([kwargs[_n] \u001b[38;5;28;01mfor\u001b[39;00m _n \u001b[38;5;129;01min\u001b[39;00m names])\n\u001b[0;32m-> 2365\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_vectorize_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sh_utils import get_shcoeff, unfold_sh_coeff, flatten_sh_coeff, apply_integrate_conv, sample_from_sh, genSurfaceNormals, cartesian_to_spherical, from_x_left_to_z_up\n",
    "from tonemapper import TonemapHDR\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "import torchvision\n",
    "import tqdm\n",
    "\n",
    "ORDER = 2\n",
    "map_name = \"117_hdrmaps_com_free_2K.exr\"\n",
    "# map_name = \"128_hdrmaps_com_free_2K.exr\"\n",
    "# map_name = \"125_hdrmaps_com_free_2K.exr\"\n",
    "\n",
    "def render(hdr_image):\n",
    "    hdr_tm, _, _ = tonemapper(hdr_image)\n",
    "\n",
    "    coeff = get_shcoeff(hdr_image, Lmax=2)\n",
    "    sh = flatten_sh_coeff(coeff, max_sh_level=2)\n",
    "\n",
    "    unfolded = unfold_sh_coeff(sh, max_sh_level=2)\n",
    "\n",
    "    apply_integrated = apply_integrate_conv(unfolded.copy())\n",
    "\n",
    "    normal_map = genSurfaceNormals(128).permute(1, 2, 0).cpu().numpy()\n",
    "    mask = (normal_map[..., 2:3] != 0)\n",
    "\n",
    "    theta, phi = cartesian_to_spherical(normal_map)\n",
    "    shading = sample_from_sh(apply_integrated, lmax=ORDER, theta=theta, phi=phi)\n",
    "\n",
    "    shading = np.float32(shading)\n",
    "    shading, _, _ = tonemapper(shading) # tonemap\n",
    "    \n",
    "    return normal_map * mask, shading * mask\n",
    "\n",
    "def fig_to_rgb_array(fig):\n",
    "    fig.canvas.draw()\n",
    "    w, h = fig.canvas.get_width_height()\n",
    "    buf = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "    return buf.reshape(h, w, 3)\n",
    "\n",
    "tonemapper = TonemapHDR()\n",
    "hdr_map = f\"/home/mint/Dev/DiFaReli++/TPAMI_baseline_MajorRevision/Neural_Gaffer/demo/environment_map_sample/{map_name}\"\n",
    "hdr_image = skimage.io.imread(hdr_map)\n",
    "hdr_image = skimage.img_as_float(hdr_image)\n",
    "\n",
    "frames = []\n",
    "for i in tqdm.tqdm(np.linspace(0, (hdr_image.shape[1] // 2), 30).astype(int)):\n",
    "    hdr_image_roll = np.roll(hdr_image.copy(), shift=-i, axis=1)\n",
    "    normal_map, shading = render(hdr_image_roll)\n",
    "    \n",
    "    # make one figure with 3 panels\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(9, 3), dpi=200)\n",
    "    axes[0].imshow(hdr_image_roll);      axes[0].set_title(\"Env (disp)\")\n",
    "    axes[1].imshow(normal_map);   axes[1].set_title(\"Normal\")\n",
    "    if shading.ndim == 2:\n",
    "        axes[2].imshow(shading, cmap=\"gray\"); axes[2].set_title(\"Shading\")\n",
    "    else:\n",
    "        axes[2].imshow(shading);              axes[2].set_title(\"Shading\")\n",
    "    for ax in axes: ax.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # convert the whole figure to an RGB numpy array and append as a frame\n",
    "    frame = fig_to_rgb_array(fig)\n",
    "    frames.append(frame)\n",
    "\n",
    "    # always close to avoid memory leaks\n",
    "    plt.close(fig)\n",
    "\n",
    "torchvision.io.write_video(\"output_video.mp4\", frames, fps=24)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural-gaffer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
